{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf03a3e8-ed6d-4acd-9bef-881a295b9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"submodules/dc-egm/src/\")\n",
    "import numpy as np\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfdf59e0-1c8a-4315-ab6c-1b0b5e1443c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcegm.solve import get_solve_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fe132e2-26bd-40ae-b39b-b46b8131b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "options_test = {\n",
    "     # mandatory\n",
    "    \"n_periods\": 50, # 25 + 50 = 75\n",
    "    \"n_discrete_choices\": 3,\n",
    "    \"n_exog_states\": 1,\n",
    "    \"quadrature_points_stochastic\": 5,\n",
    "    # custom: model structure\n",
    "    \"start_age\": 25,\n",
    "    \"resolution_age\": 60,\n",
    "    # custom: policy environment\n",
    "    \"minimum_SRA\": 67, \n",
    "    \"maximum_retirement_age\": 72,\n",
    "    \"unemployment_benefits\": 5,\n",
    "    \"pension_point_value\": 0.3,\n",
    "    \"early_retirement_penalty\": 0.036,\n",
    "    # custom: params estimated outside model\n",
    "    \"belief_update_increment\": 0.05,\n",
    "    \"gamma_0\": 10,\n",
    "    \"gamma_1\": 1,\n",
    "    \"gamma_2\": -0.1,\n",
    "    \"interest_rate\": 0.03\n",
    "}\n",
    "\n",
    "params_dict_test = {\n",
    "    \"mu\": 0.5,\n",
    "    \"delta\": 4 \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936ebfb4-72b4-49b3-9f3c-6ca24ab9366e",
   "metadata": {},
   "source": [
    "# State space - No need to be jax compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c214362-f6c1-489b-8aa8-dc99273379f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_space(options):\n",
    "    n_periods = options[\"n_periods\"]\n",
    "    n_choices = options[\"n_discrete_choices\"]\n",
    "    n_exog_states = options[\"n_exog_states\"]\n",
    "    resolution_age = options[\"resolution_age\"]\n",
    "    start_age = options[\"start_age\"]\n",
    "    belief_update_increment = options[\"belief_update_increment\"]\n",
    "    \n",
    "    # The highest policy state, we consider belongs to the expectation of the youngest.\n",
    "    n_policy_states = resolution_age - start_age\n",
    "\n",
    "    # minimum retirement age is 4 years before the lowest statutory ret age \n",
    "    min_ret_age = options[\"minimum_SRA\"] - 4\n",
    "    # maximum (conceivable) retirement age is given by lowest SRA plus the projection of the youngest\n",
    "    max_ret_age = options[\"maximum_retirement_age\"]\n",
    "    # number of possible actual retirement ages\n",
    "    n_ret_ages = max_ret_age - min_ret_age + 1\n",
    "    \n",
    "    # shape = (n_periods, n_choices, n_exog_states)\n",
    "    state_space = []\n",
    "    \n",
    "    shape = (n_periods, n_choices, n_periods, n_policy_states, n_ret_ages, 1)\n",
    "    \n",
    "    map_state_to_index = np.full(shape, fill_value=-9999, dtype=np.int64)\n",
    "    i = 0\n",
    "\n",
    "    for period in range(n_periods):\n",
    "        for lag_choice in range(n_choices):\n",
    "            # You cannot have more experience than your age\n",
    "            for exp in range(period + 1):\n",
    "                # The policy state we need to consider increases by one increment per period.\n",
    "                for policy_state in range(period + 1):\n",
    "                    for actual_retirement_id in range(n_ret_ages):\n",
    "                        age = start_age + period\n",
    "                        actual_retirement_age = min_ret_age + actual_retirement_id\n",
    "                        # You cannot retire before the earliest retirement age\n",
    "                        if (age <= min_ret_age) & (lag_choice == 2):\n",
    "                            continue\n",
    "                        # After the maximum retirement age, you must be retired\n",
    "                        elif (age > max_ret_age) & (lag_choice != 2):\n",
    "                            continue\n",
    "                        # If you weren't retired last period, your actual retirement age is kept at minimum\n",
    "                        elif (lag_choice != 2) & (actual_retirement_id > 0):\n",
    "                            continue\n",
    "                        # If you are retired, your actual retirement age can at most be your current age    \n",
    "                        elif (lag_choice == 2) & (age <= actual_retirement_age):\n",
    "                            continue\n",
    "                        # Starting from resolution age, there is no more adding of policy states. \n",
    "                        elif policy_state > n_policy_states - 1:\n",
    "                            continue\n",
    "                        # If you have not worked last period, you can't have worked all your live \n",
    "                        elif (lag_choice != 1) & (period == exp) & (period > 0):\n",
    "                            continue\n",
    "                        else:\n",
    "                            state_space += [[period, lag_choice, exp, policy_state, actual_retirement_age, 0]]\n",
    "                            map_state_to_index[period, lag_choice, exp, policy_state, actual_retirement_id, 0] = i\n",
    "                            i += 1\n",
    "\n",
    "    return np.array(state_space), map_state_to_index\n",
    "\n",
    "\n",
    "def get_choice_set(state, map_state_to_index):\n",
    "    #Todo: replace hard coded parameters\n",
    "    #Todo: everything dependent on policy state (e.g. can only retire 4 years before SRA)\n",
    "    \n",
    "    # if you're younger than min SRA, you cannot retire\n",
    "    if state[0] < 63 - 25:\n",
    "        return np.array([0, 1])\n",
    "     # After the maximum retirement age, you must be retired\n",
    "    elif state[0] > 73 - 25:\n",
    "        return np.array([2])\n",
    "    # retirement is absorbing\n",
    "    elif state[1] == 2:\n",
    "        return np.array([2])\n",
    "    else:\n",
    "        return np.array([0, 1, 2])\n",
    "    \n",
    "def update_state(state, choice):\n",
    "    state_next = state.copy()\n",
    "    \n",
    "    # age increases by one\n",
    "    state_next[0] += 1\n",
    "    \n",
    "    # Set choice as lag choice in next state\n",
    "    state_next[1] = choice\n",
    "    \n",
    "    # experience increases by one if working\n",
    "    if choice == 1:\n",
    "        state_next[2] += 1\n",
    "    \n",
    "    # expected SRA increases by one increment\n",
    "    if state[0] + 25 < 60:\n",
    "        state_next[3] += 1\n",
    "        \n",
    "    return state_next\n",
    "\n",
    "state_space_functions = {\n",
    "        \"create_state_space\": create_state_space,\n",
    "        \"get_state_specific_choice_set\": get_choice_set,\n",
    "        \"update_endog_state_by_state_and_choice\": update_state,\n",
    "    }\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b5f202-8a70-4f60-a12e-86befcf2c5bd",
   "metadata": {},
   "source": [
    "# Utility funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84fd7758-22e9-4828-861f-e7f0a9784740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_func(consumption, choice, params_dict):\n",
    "    mu = params_dict[\"mu\"]\n",
    "    delta = params_dict[\"delta\"]\n",
    "    is_working = choice == 1\n",
    "    utility = consumption ** (1- mu) / (1 - mu) - delta * is_working\n",
    "    return utility\n",
    "\n",
    "\n",
    "def marg_utility(consumption, params_dict):\n",
    "    mu = params_dict[\"mu\"]\n",
    "    marg_util = consumption ** -mu\n",
    "    return marg_util\n",
    "\n",
    "\n",
    "def inverse_marginal(marginal_utility, params_dict):\n",
    "    mu = params_dict[\"mu\"]\n",
    "    return marginal_utility ** (-1/mu)\n",
    "\n",
    "\n",
    "utility_functions = {\n",
    "        \"utility\": utility_func,\n",
    "        \"inverse_marginal_utility\": inverse_marginal,\n",
    "        \"marginal_utility\": marg_utility,\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6754ae59",
   "metadata": {},
   "source": [
    "# Last Period Utility (e.g. Bequest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce29130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_final_period_scalar(\n",
    "    state_vec,\n",
    "    choice,\n",
    "    begin_of_period_resources,\n",
    "    params,\n",
    "    options,\n",
    "    compute_utility,\n",
    "    compute_marginal_utility,\n",
    "):\n",
    "    \"\"\"Compute optimal consumption policy and value function in the final period.\n",
    "\n",
    "    In the last period, everything is consumed, i.e. consumption = savings.\n",
    "\n",
    "    Args:\n",
    "        state (np.ndarray): 1d array of shape (n_state_variables,) containing the\n",
    "            period-specific state vector.\n",
    "        choice (int): The agent's choice in the current period.\n",
    "        begin_of_period_resources (float): The agent's begin of period resources.\n",
    "        compute_utility (callable): Function for computation of agent's utility.\n",
    "        compute_marginal_utility (callable): Function for computation of agent's\n",
    "        params (dict): Dictionary of model parameters.\n",
    "        options (dict): Options dictionary.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "\n",
    "        - consumption (float): The agent's consumption in the final period.\n",
    "        - value (float): The agent's value in the final period.\n",
    "        - marginal_utility (float): The agent's marginal utility .\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # eat everything\n",
    "    consumption = begin_of_period_resources\n",
    "    \n",
    "    # utility & marginal utility of eating everything\n",
    "    value = compute_utility(consumption=begin_of_period_resources, choice=choice, params_dict=params)\n",
    "    \n",
    "    marginal_utility = compute_marginal_utility(\n",
    "        consumption=begin_of_period_resources, params_dict=params\n",
    "    )\n",
    "\n",
    "    return marginal_utility, value, consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b566776",
   "metadata": {},
   "source": [
    "# Budget Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc958db6-5350-44ea-bea1-254eecc64c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def budget_constraint(state_beginning_of_period, # s_t, with d_{t-1} at s_t[1]\n",
    "                      savings_end_of_previous_period, # A_{t-1}\n",
    "                      income_shock_previous_period, # epsilon_{t - 1}\n",
    "                      params,\n",
    "                      options):\n",
    "    \n",
    "    \n",
    "    # fetch necessary parameters (gammas for wage, lambdas & ERP for pension)\n",
    "    gamma_0 = options[\"gamma_0\"]\n",
    "    gamma_1 = options[\"gamma_1\"]\n",
    "    gamma_2 = options[\"gamma_2\"]\n",
    "    lambd = options[\"pension_point_value\"]\n",
    "    ERP = options[\"early_retirement_penalty\"]\n",
    "    \n",
    "    # read out state\n",
    "    age = state_beginning_of_period[0]\n",
    "    lag_choice = state_beginning_of_period[1]\n",
    "    experience = state_beginning_of_period[2]\n",
    "    SRA_at_resolution = options[\"minimum_SRA\"] + state_beginning_of_period[3]*options[\"belief_update_increment\"]\n",
    "    actual_retirement_age = 68 # B: das hier fehlt noch im state space\n",
    "    \n",
    "    # calculate applicable SRA and pension deduction/increase factor \n",
    "    # (malus for early retirement, bonus for late retirement)\n",
    "    \n",
    "    pension_factor = 1 - (actual_retirement_age - SRA_at_resolution)*ERP \n",
    "    \n",
    "    # decision bools\n",
    "    is_unemployed = lag_choice==0 \n",
    "    is_worker = lag_choice==1\n",
    "    is_retired = lag_choice==2\n",
    "    \n",
    "    # decision-specific income\n",
    "    unemployment_benefits = options[\"unemployment_benefits\"]\n",
    "    labor_income = gamma_0 + gamma_1*experience + gamma_2*experience**2 + income_shock_previous_period \n",
    "    retirement_income = lambd*experience*pension_factor \n",
    "    \n",
    "    income = is_unemployed * unemployment_benefits + is_worker * labor_income + is_retired * retirement_income\n",
    "    \n",
    "    # calculate beginning of period wealth M_t\n",
    "    wealth = (1 + options[\"interest_rate\"]) * savings_end_of_previous_period + income\n",
    "    \n",
    "    return wealth\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f171e2",
   "metadata": {},
   "source": [
    "# State Space and Budget Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab924beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.219000000000001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state-space test\n",
    "\n",
    "state_space, indexer = create_state_space(options_test)\n",
    "\n",
    "\n",
    "budget_constraint(state_beginning_of_period=state_space[47226,:], # s_t, with d_{t-1} at s_t[1]\n",
    "                      savings_end_of_previous_period=10, # A_{t-1}\n",
    "                      income_shock_previous_period=0.5, # epsilon_{t - 1}\n",
    "                      params=params_dict_test,\n",
    "                      options=options_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a428c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer[35,2,20,10,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a5b5766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42,  2, 11,  0, 65,  0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_space[61043,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a3996af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_periods': 50,\n",
       " 'n_discrete_choices': 3,\n",
       " 'n_exog_states': 1,\n",
       " 'start_age': 25,\n",
       " 'resolution_age': 60,\n",
       " 'minimum_SRA': 67,\n",
       " 'maximum_retirement_age': 72,\n",
       " 'unemployment_benefits': 5,\n",
       " 'pension_point_value': 0.3,\n",
       " 'early_retirement_penalty': 0.036,\n",
       " 'belief_update_increment': 0.05,\n",
       " 'gamma_0': 10,\n",
       " 'gamma_1': 1,\n",
       " 'gamma_2': -0.1,\n",
       " 'interest_rate': 0.03}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c424efe0",
   "metadata": {},
   "source": [
    "# Dumm exog process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764c7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_exog(state, params_dict):\n",
    "    return np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dac4320-86d4-4a3c-afbb-e31583f77181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0, 63,  0],\n",
       "       [ 0,  1,  0,  0, 63,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_space, map_state_to_index = create_state_space(options_test)\n",
    "period_to_inspect = 0\n",
    "\n",
    "state_space[state_space[:, 0] == period_to_inspect]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee16742c",
   "metadata": {},
   "source": [
    "# Exogenous Savings Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a205d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "savings_grid=jnp.arange(start=0,stop=100,step=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dfd1d1",
   "metadata": {},
   "source": [
    "# Call DCEGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9f53c96-2e0a-4163-bc92-54f5ec090998",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_solve_function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9da4ad7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_solve_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mexog_savings_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msavings_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mutility_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutility_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbudget_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbudget_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mstate_space_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_space_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mfinal_period_solution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolve_final_period_scalar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtransition_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_exog\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\01_Documents\\02_University\\04_PhD_BSE\\papers\\policy_uncertainty\\model_development\\submodules/dc-egm/src\\dcegm\\solve.py:93\u001b[0m, in \u001b[0;36mget_solve_function\u001b[1;34m(options, exog_savings_grid, utility_functions, budget_constraint, state_space_functions, final_period_solution, transition_function)\u001b[0m\n\u001b[0;32m     85\u001b[0m create_state_space \u001b[38;5;241m=\u001b[39m state_space_functions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_state_space\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     87\u001b[0m state_space, map_state_to_state_space_index \u001b[38;5;241m=\u001b[39m create_state_space(options)\n\u001b[0;32m     88\u001b[0m (\n\u001b[0;32m     89\u001b[0m     state_choice_space,\n\u001b[0;32m     90\u001b[0m     map_state_choice_vec_to_parent_state,\n\u001b[0;32m     91\u001b[0m     reshape_state_choice_vec_to_mat,\n\u001b[0;32m     92\u001b[0m     transform_between_state_and_state_choice_space,\n\u001b[1;32m---> 93\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_state_choice_space\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_state_to_state_space_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_space_functions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget_state_specific_choice_set\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m final_period_solution_partial \u001b[38;5;241m=\u001b[39m partial(\n\u001b[0;32m    100\u001b[0m     final_period_solution,\n\u001b[0;32m    101\u001b[0m     compute_utility\u001b[38;5;241m=\u001b[39mcompute_utility,\n\u001b[0;32m    102\u001b[0m     compute_marginal_utility\u001b[38;5;241m=\u001b[39mcompute_marginal_utility,\n\u001b[0;32m    103\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    104\u001b[0m )\n\u001b[0;32m    106\u001b[0m period_specific_state_objects \u001b[38;5;241m=\u001b[39m create_period_state_and_state_choice_objects(\n\u001b[0;32m    107\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    108\u001b[0m     state_space\u001b[38;5;241m=\u001b[39mstate_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m     transform_between_state_and_state_choice_space\u001b[38;5;241m=\u001b[39mtransform_between_state_and_state_choice_space,\n\u001b[0;32m    113\u001b[0m )\n",
      "File \u001b[1;32m~\\OneDrive\\01_Documents\\02_University\\04_PhD_BSE\\papers\\policy_uncertainty\\model_development\\submodules/dc-egm/src\\dcegm\\state_space.py:60\u001b[0m, in \u001b[0;36mcreate_state_choice_space\u001b[1;34m(state_space, map_state_to_state_space_index, get_state_specific_choice_set)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create state choice space of all feasible state-choice combinations.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03mAlso conditional on any realization of exogenous processes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m n_states, n_state_and_exog_variables \u001b[38;5;241m=\u001b[39m state_space\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m---> 60\u001b[0m _n_periods, n_choices, _n_exog_processes \u001b[38;5;241m=\u001b[39m map_state_to_state_space_index\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     62\u001b[0m state_choice_space \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m     63\u001b[0m     (n_states \u001b[38;5;241m*\u001b[39m n_choices, n_state_and_exog_variables \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     64\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     67\u001b[0m map_state_choice_vec_to_parent_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_states \u001b[38;5;241m*\u001b[39m n_choices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "get_solve_function(options=options_test, \n",
    "                  exog_savings_grid=savings_grid,\n",
    "                  utility_functions=utility_functions,\n",
    "                  budget_constraint=budget_constraint,\n",
    "                  state_space_functions=state_space_functions,\n",
    "                  final_period_solution=solve_final_period_scalar,\n",
    "                  transition_function=dummy_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04242f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
